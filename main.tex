\documentclass{sigchi}

% Use this command to override the default ACM copyright statement (e.g. for preprints). 
% Consult the conference website for the camera-ready copyright statement.
\toappear{
	Submitted for review.
}

% Arabic page numbers for submission. 
% Remove this line to eliminate page numbers for the camera ready copy
\pagenumbering{arabic}

% Load basic packages
\usepackage{balance}  % to better equalize the last page
\usepackage{graphics} % for EPS, load graphicx instead
\usepackage{times}    % comment if you want LaTeX's default font
%\renewcommand{\ttdefault}{cmtt}
%\usepackage{fontspec}
%\setmainfont{Cardo}
\usepackage{url}      % llt: nicely formatted URLs

% llt: Define a global style for URLs, rather that the default one
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\small\bf\ttfamily}}}
\makeatother
\urlstyle{leo}


% To make various LaTeX processors do the right thing with page size.
\def\pprw{8.5in}
\def\pprh{11in}
\special{papersize=\pprw,\pprh}
\setlength{\paperwidth}{\pprw}
\setlength{\paperheight}{\pprh}
\setlength{\pdfpagewidth}{\pprw}
\setlength{\pdfpageheight}{\pprh}

% Make sure hyperref comes last of your loaded packages, 
% to give it a fighting chance of not being over-written, 
% since its job is to redefine many LaTeX commands.
\usepackage[pdftex]{hyperref}
\hypersetup{
pdftitle={SIGCHI Conference Proceedings Format},
pdfauthor={LaTeX},
pdfkeywords={SIGCHI, proceedings, archival format},
bookmarksnumbered,
pdfstartview={FitH},
colorlinks,
citecolor=black,
filecolor=black,
linkcolor=black,
urlcolor=black,
breaklinks=true,
}

% create a shortcut to typeset table headings
\newcommand\tabhead[1]{\small\textbf{#1}}


% End of preamble. Here it comes the document.
\begin{document}

\title{DeduceIt! Automatically Guiding Students through Derivations in a Massively Open On-line Course}

\numberofauthors{1}
\author{
  \alignauthor Ethan Fast, Colleen Lee, Daphne Koller, Michael Bernstein, Alex Aiken\\
    \affaddr{Stanford University}\\
    \email{\{ethan.fast, clee0, koller, aiken, msb\}@cs.stanford.edu}\\
}

\maketitle

\begin{abstract}
This paper presents DeduceIt, a derivation checking system for massively open on-line courses. DeduceIt is a general system for creating and grading student assignments---it guides students through exercises which can be defined by instructors across arbitrary formal domains---but unlike other interactive theorem provers, it presents a web-based interface accessible to non-expert users, and it can be used by instructors and students without prior training. DeduceIt also introduces the idea of a \textit{proof cache}, a novel data structure which leverages a crowd of students to decrease the cost of checking derivations and providing real-time, constructive feedback. We describe our experience using DeduceIt and evaluate the system with data collected from thousands of students in an on-line class.
\end{abstract}

\keywords{
	\textcolor{red}{What keywords to use?}
}

\category{H.5.m.}{Information Interfaces and Presentation (e.g. HCI)}{Miscellaneous}

% See: \url{http://www.acm.org/about/class/1998/}
% \textcolor{red}{Mandatory}

\terms{
	Human Factors; Design; Measurement. 
}

% \url{http://www.sheridanprinting.com/sigchi/generalterms.htm}.
% \textcolor{red}{Optional section to be included in your final version.}

\section{Introduction}
As instructors begin to teach hundreds of thousands of students in on-line classrooms, it becomes increasingly difficult for them to grade complex assignments and provide students with personal feedback. Here, the rise of massively open on-line courses (MOOCs) presents a departure from the standard educational model: TAs are not designed to scale. 

% In some ways this is not a problem. Often when one student is stuck on an assignment, or fails to understand a lecture, another more knowledgable student will step in to help. Our experience instructing an on-line Compilers class suggests that communities form dynamically around on-line courses, providing students with an emergent network of peer support.

% However, student communities cannot entirely replace the roles Professors and TAs. Even the most capable of students will tend to lack the domain knowledge of the instructor, and when feedback occurs---usually on some kind of forum--

When the size of an on-line course increases, the attention of its instructors and TAs necessarily becomes more scarce. They are unable to provide large numbers of students---to date the largest MOOC has enrolled more than 180,000---with feedback on their assignments; much less to present it in real-time. In particular, grading becomes intractable unless it is automated, which it often cannot be, particularly in complex domains where students may construct correct solutions in many different ways. 

These constraints are important limitations to the MOOC model. Students tend to learn better when subject to tight feedback loops [?], and many subjects, if taken in a traditional course, grade students on proofs or derivations, where there are many ways to describe a correct answer.

MOOC platforms have attempted to automate away some of these issues, but providing thousands of students with \textit{constructive} and \textit{real-time} feedback has remained an unsolved problem. Coursera and Udacity give instructors out-of-the-box tools to build assignments and quizzes with automated grading features, but these tools lack flexibility: evaluation is constrained to discrete, instructor-specified solutions and offers students a limited feedback loop (e.g. ``correct," or ``incorrect"). For technical, mathematical, or scientific domains where assignment solutions are often \textit{derivations}---many-staged and prone to individual variation---this limitation is particularly problematic.

To address these limitations we present:
%(e.g. in our Compilers course we use it to assign problems in type checking, regular expressions, finite automata, and many other topics; its generality allows its use in most formal systems).
\begin{itemize}
\item The \textit{DeduceIt} system: A web-based framework in which it is possible to specify a general class of derivation exercises, yet which remains accessible non-expert users. DeduceIt provides students with constructive and real-time feedback.
\item The idea of a \textit{proof cache}: A novel data structure which records the history of every attempted derivation, reusing computations from previously derived steps to provide predictable performance under heavy load and enable real-time feedback on student progress. We show this cache can increase system efficiency by several orders of magnitude.
\item An \textit{empirical evaluation} of DeduceIt: A report on the data we have collected from a massive on-line class with thousands of students doing dozens of exercises.
\end{itemize}

The rest of this paper is organized as follows: We begin with related work and a motivating example, then present DeduceIt's interface and capabilities. Next, we describe the underlying architecture of the system and provide an empirical evaluation, using data collected from thousands of students in an on-line class. We close with reflections, conclusions, and future work.

\section{Related Work}
There is quite a bit of related work on proof solving systems and derivation helpers. Several existing tools already provide users with rich and automated feedback as they work through a derivation, but these tools are principally designed for expert users and unsuited to the MOOC audience. For instance, the X tool and the Y tool might allow experts to explore problem domains in predicate logic or mathematics, but their interfaces are not designed to be accessible to lay students, or even to a typical course instructor. 

Moreover, automatic feedback and grading systems are often domain-specific and do not grant an instructor sufficient flexibility in defining a set of disparate problems. Sometimes this approach works well: automated grading systems have long evaluated student program code in computer science departments (and now also commercially). But we are concerned here with more general systems.

\section{Motivating Example}

To better motivate how DeduceIt works and what problems it solves, we begin with an example assignment from the perspective of a MOOC student in Coursera's Compilers class. This student has recently finished her first week in the course, where she has learned among other things about the properties of regular expressions.

In this particular assignment we ask her to show equality between two regular expressions. Assuming $+$, $*$, and $.$ as union, kleen closure, and concatenation, she must prove:
$$(A+B)* \equiv ((B+A).(B+A)*)+\epsilon$$
More concretely, the assignment asks our student to derive a particular expression. DeduceIt labels this the \textit{goal}: 
$$((B+A).(B+A)*)+\epsilon$$ 
To show the goal expression, our student must start from certain other expression(s). DeduceIt calls these the \textit{givens}, and here they consist of the single starting expression: 
$$(A+B)*$$
Our student also sees a description of the assignment and---perhaps most importantly---the available \textit{rules} she may apply on the given expressions (or in some cases, sub-expressions of these givens) in order to derive the final, goal expression. In this assignment these rules specify several equality preserving transformations of regular expressions: Commutativity, Distributivity, Right Distributivity, Unfold, Identity, Left Identity, and Absorption. However, rules may not always preserve equality in general.

To complete a step in the derivation, our student may apply a rule to one or more given expressions, producing a new \textit{conclusion}. As the derivation expands, the conclusion of each previous step is added to the set of givens. DeduceIt can provide several different kinds of feedback on each step, depending on the state of the derivation. Next, we will walk through a few such steps.

\subsection{Completing a Derivation}
As she reads over the assignment, our student realizes she has only been given one expression from which to start her derivation: $(A+B)∗$. She reasons this must go in the givens input field on the first step. (In fact, this is the only expression DeduceIt allows her to enter in that field). Now she has two input fields left. One asks for a rule; the other a conclusion. To come up with a conclusion, she must decide which rule to apply, and where to apply it. She supposes ``Unfold" looks promising and tries it on the full starting expression, computing:
$$((A + B).(A + B)*)+\epsilon$$
This expression looks pretty close to her goal, so she enters it in the conclusion input field. After selecting ``Unfold" as her rule, she tells DeduceIt to update her derivation. There is a brief computation, then the derivation returns with her previous step highlighted in green: it was successful. A new step lies below her previous entry---this one is empty---querying her for the next line of the derivation.

Our student now considers her previous conclusion: since it is nearly identical to the goal, she wants to use it for her next step. If she can transform its two sub-expressions $A+B$ to $B+A$, then she will have proven the goal and completed the assignment. While she is pretty sure one property of regular expressions does allow for this kind of transformation, she can't remember what it is called. So she looks through the assignment rules and sees it: Commutativity! Regular expressions are commutative under union.

Mentally, she applies Commutativity to each of the two $A+B$ sub-expressions, then enters her result in the conclusion input box on the next line of the derivation. This conclusion is identical to the goal expression: 
$$((B+A).(B+A)*)+\epsilon$$
She selects ``Commutativity" from the rule input box, chooses the conclusion from her previous step $((B+A).(B+A)*)+\epsilon$ as her new given, and tells DeduceIt to  update her proof. DeduceIt checks her derivation, infers through proof search that she means to apply Commutativity twice---on the two appropriate sub-expressions---and responds that the derivation is correct: she has completed this assignment.


\section{How DeduceIt Works}

We begin this section with background information about term rewriting systems, then we present an overview of DeduceIt's two primary interfaces: the instructor view and the student view.

\subsection{Term Rewriting Systems}

DeduceIt uses a term rewriting system to verify student derivations. In general, a rewriting system consists of a set of objects and relations which define transformations on those objects; each transformation is called a rewrite rule. A \textit{term} rewriting system is a rewriting system which operates on expressions with nested sub-expressions.

Term rewrite rules define transformations which occur between terms. These rules have a left side, which must match a term for the rule to be applied, and a right side, which defines the new expression produced by the rule. Variables may appear in the rule (declared in the system with $\$$ notation) which bind to the term or its subexpressions. For example, in a language which supports integers, symbols, and the binary operators $+$, $-$, and $=$ (this happens to be a subset of the default DeduceIt language), one such rule might be: $(\$x+\$y=\$z) \rightarrow (\$x=\$z-\$y)$. The system can apply this rule to the expression $2+1=3$ to produce $2=3-1$.

While DeduceIt's derivation checker operates primarily as a term rewriting system, it differs from a standard system in several respects. First, DeduceIt supports an assumption of equality in certain rewrites, where specified by an instructor. Rewrite rules which assume equality (declared with $:=$ instead of $\rightarrow$) can be applied recursively upon term subexpressions; the entire term need not match the rule, but only a subexpression of that term. This makes DeduceIt more efficient at verifying certain common derivations. Second, DeduceIt supports the dynamic evaluation of basic mathematical expressions. For instance, if DeduceIt is provided with a set of rules which govern basic algebra and the expression $x=3-1$, it can derive $x=2$ by using the dynamic rule $\$x-\$y := eval(\$x-\$y)$. This rewrite is also an example of a rule which assumes equality.

\subsection{The instructor view}

The assignment construction page is the most complex portion of DeduceIt's interface. To create an assignment, an instructor must specify four things: 
  \begin{enumerate}
  \item A rewrite language: DeduceIt provides every assignment with a default rewrite language composed of variables, symbols, integers, and several common unary and binary operators. In many assignment domains this will be sufficient, but an instructor may optionally augment the language with extra syntax for functions and constants. 
  \item The Rulesets: These are named sets of rewrite rules which a student may apply while working through an assignment's derivation. One ruleset corresponds to many underlying rewrite rules. This is necessary because an instructor may want to refer to several distinct rules by the same name (e.g. $1*X \rightarrow X$ and $X*1 \rightarrow X$ are two distinct rewrite rules which both describe the multiplicative identity.)
  \item The given expression(s): A set of expressions which serve as the starting point of a derivation.
  \item The goal expression: The desired result of a derivation.
  \end{enumerate}

A student works through an assignment by starting from the given expressions and applying valid transformations until she has reached the goal expression.

\subsubsection{The Language}

DeduceIt's default language should be familiar to anyone who has used an advanced calculator. It ships with the unary operators $\char`\~$ and $-$, and the binary operators $.$, $\&$, $|$, $,$, $*$, $\backslash$, $+$, $-$, $=$, $\neq$, $\leq$, $\geq$, $<$, $>$, $:=$, and $\rightarrow$ which we list in order of precedence. DeduceIt also supports variables (these may only be used when defining rewrite rules), symbols, and integers. For example, here are three legal expressions in the default rewrite language are: 
$$\$p,(\$p=>\$q)\rightarrow{}\$q$$ 
$$a.b.b.a$$
$$x+2=y$$ 
Note that with three exceptions (the notation specific to rewrites: $:=$, $\rightarrow$, and $\$$) the operators used in these expressions have no meaning without an accompanying set of rules; they simply determine the parsing of an expression.

Instructors may add two kinds of syntax to DeduceIt's standard rewrite language: constants and variable argument functions. This is convenient in many domains, where familiarly named functions and constants enhance the readability of an assignment. For these custom functions and constants DeduceIt adopts a notation inspired by latex. Constants appear in the language as a symbol value preceded by a backslash, e.g $\backslash{}e$. Functions look much the same, except they have arguments which they accept in brackets, e.g. $\backslash{}sin\{x\}$. Figure 0 shows DeduceIt's custom syntax creation view.


\subsubsection{Rulesets}

Rulesets are the most complicated part of an assignment. They define the sets of valid transformations which a student may use in a derivation. Each ruleset has a name, a student-facing description, a set of rewrite rules, and an optional set of constraints. The name and description of a ruleset are all a student sees when using DeduceIt, and these fields  make an assignment more accessible; students do not need to understand rewrite rules to use the system.

Each rewrite rule in a ruleset is either a strict rewrite rule or an equality. To apply a strict rewrite rule, its left side must match exactly on an expression, wheres an equality may be applied to an expression or any of its subexpressions. Take as an example the expression $1+y*y=5$ and the strict rewrite rule $\$x*\$x \rightarrow \$x^2$; here the rewrite rule cannot be applied, since its left side doesn't bind with the entire expression. However, a similar rewrite rule which has been defined with an assumption of equality, $\$x*\$x := \$x^2$, will bind on $y*y$ and produce the transformation $1+y^2=5$. In this way equalities are more powerful than strict rewrite rules, and for many assignments a single equality can take the place of many strict rules. This eases the burden on an instructor and usually speeds up proof search; the more rules an assignment has, the slower search tends to be.

Various constraints may be defined on the variable terms used in the ruleset. They operate in a manner similar to conditional rewrite rules, but are somewhat less general; we use only containment---whether or not a variable contains certain other terms---as a condition on ruleset application.

A ruleset may also be either ``required" or ``free." While a required ruleset must be named explicitly when a student uses it in a derivation, a ``free" ruleset may be elided. Behind the scenes, DeduceIt will attempt to fill in such ``free" steps automatically through proof search. This is useful when a student must use trivial transformations which are necessary to the derivation but unimportant to the assignment. For example, a student may want to rearrange terms in a mathematical expression as part of some broader rule application. DeduceIt's ``free" rules allow the student to skip over these steps.  

In figure 0 we show DeduceIt's Ruleset creation view.

\subsubsection{Sharing Rewrite Languages}

Some rewrite languages are common enough that it makes sense to share them among different assignments: for instance, many assignments might use the languages defined for basic algebraic manipulation, predicate logic, or the expansion of regular expressions. DeduceIt allows instructors to reuse a rewrite language across assignments.

\subsubsection{The Assignment Proof Tree}

For each assignment, an instructor has real-time access to its proof tree. This tree tracks the history of all derivations associated with the assignment. These derivations share a common root node, and each step in a derivation maps to one of its children, the immediate parent of which is either the root node itself or else a node associated with the previously derived step. Every node keeps track of derivation state information and a count of how many students have traversed it. An instructor may annotate any node in the tree with hints, and these will be visible to a student if she enters upon that path in her own derivation. An instructor may also use this tree to override the behavior of the underlying derivation checker, e.g. forcibly label a given derivation step valid. This can be useful for steps which make use of particularly long chains of free rules which can't be discovered and verified by proof search.


\subsection{The student view}

An assignment's student view presents the information we have already encountered on the instructor interface. At the top of the page a title, goal, and description broadly introduce the exercise at hand. Below these are the given expressions---a student uses one or more of these to start the derivation---and some number of rulesets divided into two types: required and free. Rulesets may be (and usually are) composed of many separate rewrite rules, but an assignment presents them as single, discrete entities; students need not be familiar with rewriting systems to use DeduceIt. In fact, the term `rewrite' cannot be found anywhere on the student view, and these rulesets are themselves labeled on the page simply as `rules'. This might create a leaky abstraction if rulesets are not carefully specified (i.e. the instructor description does not exactly match the behavior specified by the underlying rewrites), but most students are not familiar with rewrite rules, and we have discovered that a small sacrifice of precision in the rules positively impacts usability, as reported by several students.

\subsubsection{Interacting with a Derivation}

Each assignment page contains an interactive derivation. Before a student has made progress in an assignment this derivation consists of only three empty input fields which are labeled: conclusion, rule, and givens. To more forward in a derivation, a student must derive a conclusion by applying the selected rule on the selected givens(s). 

This derivation interface constrains students in several respects. First, students may select only expressions which they have already derived (or which are members of the set of starting givens) from the givens input field. Likewise, students may only select rules which are associated with the current assignment from the rules input field. These constrains eliminate the possibility of many simple mistakes, like mistypings, which we found surprisingly common in an earlier prototype of the system. The conclusion input field is unconstrained, however, and students can type into it any kind of expression they wish.

To verify the current state of a derivation, students must click on the button ``Update Proof." DeduceIt will respond with one of several kinds of feedback: if the derivation is so far valid, all its steps will turn green; if the system cannot parse the conclusion of some step in the derivation, that step will turn yellow; or if the system can parse but not prove the conclusion of some step in the derivation, that step will turn red. Each valid step preceding an invalid step will remain green, and if an invalid step has any hint annotations on the assignment Proof Tree, hints appear adjacent to that step. Hints take the form of a styled question mark, which expands into text on mouseover. Finally, if the conclusion of the latest step is equivalent to the goal expression, DeduceIt signals the assignment is finished with a large checkmark and does not prompt a new step in the derivation.

\subsection{Extensions to the Derivation Interface}

We experimented with several other forms of derivation feedback which we have not yet deployed for our on-line class.

\subsubsection{Surfacing the Proof Path}

DeduceIt maintains aggregate data about every derivation, so the system knows when students are proceeding down well-traveled paths in a derivation, or down correct but---so far---more lengthy paths, or down paths which have not yet led to the goal. One version of DeduceIt surfaces this information with a status indicator, a colored circle of green, yellow, or orange at the top of the derivation, indicating whether students are on a common path, an uncommon but successful path, or an as yet unsuccessful path. 

From anecdotal feedback, it seems students find this indicator helpful, and in theory DeduceIt could provide students even finer grain information: the exact number of other successful or unsuccessful students who have worked to the current state of their derivation; or detection of the exact step in their derivation where they left the well-traveled path. It is also possible to further process the Proof Tree. By collapsing some nodes which are syntactically different but semantically equivalent (e.g. the expressions $(1+2)+3$ and $1+(2+3)$ in a calculus assignment) DeduceIt could construct a more meaningful notion of a derivation path.

\subsubsection{Providing Automatic Hints}

DeduceIt allows instructors to set up hints for any derivation step by annotating an assignment's proof tree. However, we built another version of DeduceIt that constructs these hints automatically using proof search. In this second implementation, DeduceIt holds the rule and assumption fields constant and searches for alternative valid conclusions. 

For instance, suppose a student enters $x=3+1$, \textit{Balance Equation}, and $x+1=3$ in the respective fields for conclusion, rule, and assumptions. This is an incorrect step, so DeduceIt will highlight it in red. And in the standard version of DeduceIt, if an instructor has not annotated this step on the proof tree, this is all the system will do. The student will not be given any further direction; she knows only the step is wrong. However, the hint-generating DeduceIt is able to give her more specific feedback, e.g. ``Your conclusion is incorrect." In this example proof search finds a viable alternative conclusion, $x=3-1$, which matches the rule and assumption the student entered, so DeduceIt knows it is possible to apply the selected rule upon the selected assumptions.

Other hint-generating systems might hold constant different parts of the derivation (e.g. searching for rules and assumptions to match a given conclusion), or leverage the Proof Tree to provide students with hints particular to common derivation paths. It is important to us that the system provide useful hints without giving away too much information: a tricky balance to achieve in an automated system. Hint generation is the subject of ongoing work.

\section{The Internals of DeduceIt}


DeduceIt is a system formed of three distinct components: a frontend interface, a backend theorem prover, and a database. The frontend manages all user interactions (for both students and instructors) as described in the previous section, the backend theorem prover exposes an on-line API which the frontend calls---when necessary---to check student derivations, and the database stores all the data associated with users and assignments, including the Proof Cache.

We built these components using several technologies and cloud providers. The frontend is a Ruby on Rails web application deployed on Heroku, the backend is a Haskell application also deployed on Heroku, and the database is a MongoDB installation running on MongoHQ. Each of these components can be scaled to serve arbitrary numbers of students.

\subsection{The Theorem Prover}

To verify student derivations, DeduceIt applies proof search over a term rewriting system. Its system differs from a standard rewriting system in that it supports rulesets (i.e. named groups of rewrite rules), equalities, dynamic evaluation for some term expressions, and containment conditions on the application of certain rewrites. We discussed each of these features in the previous section. 

DeduceIt's theorem prover also includes a parser which the system constructs dynamically, per API call. This allows instructors to define custom assignment syntax. DeduceIt uses the parser to deconstruct an API call into expression terms of the rewrite language. 

\subsubsection{The Theorem Prover API}

The DeduceIt prover is wrapped in web server which can be queried via API on the following POST parameters: \textit{rulesets}, \textit{assumptions}, \textit{syntax}, and \textit{conclusion}. To every query the prover will respond with either ``proven", ``unproven'', or ``syntax error.'' The frontend uses this API to assess the validity of each step in a derivation.

The API parameters function much as their names suggest. The \textit{syntax} parameter defines any new syntax on the default rewrite language. The rest are used for proof search: DeduceIt tries to prove the provided \textit{conclusion} expression using the set of rewrite rules defined in \textit{rulesets} on the starting expressions in \textit{assumptions} (that is, assuming all these parameters parse). 

Although in the previous section we mentioned a student can select only one ruleset for each step of a derivation, it is usually necessary to pass the backend prover more than one. This is necessary because the prover requires not only the ruleset selected on the given step, but also any other rulesets which are declared ``free." Free rulesets are always allowed for any step of the derivation; in general they tend to be common or trivial transformations, orthogonal to the didactic goals of an assignment. 

In figure 0 we show an example API query.

\subsubsection{Proof Search}

In DeduceIt, proof search works by applying rewrite rules iteratively upon a group of expressions to generate new expressions. In general, a search may be considered either \textit{forward}, starting from the known expressions and working toward the desired expressions, or \textit{backward}, starting from the desired expressions and working toward the known expressions with an inverted set of rules. DeduceIt supports both kinds of search. 

For example, suppose we give DeduceIt the assumption $a$, the rewrite rule $a \rightarrow a.a$, and the conclusion $a.a.a$. The system may conduct a forward search: start from $a$ and apply the rule twice, first producing $a.a$ and then $a.a.a$. Or it may search backward: construct a new rule $a.a \rightarrow a$ (the inverse of the old rule) and start from $a.a.a$, and then apply this new rule twice to produce $a.a$ and then $a$. Either method leads the system to declare the step valid.

In practice, DeduceIt conducts one round of forward search and one round of backward search; the two rounds of search then meet in the middle, i.e. they check for terms generated in common. We introduce backward search to ensure DeduceIt will correctly check rewrite languages which allow the introduction of new symbols, e.g. predicate logic and the rule $\$a \rightarrow \$a \vee \$b$ (note here that $\$b$ is a variable in the rewrite rule which binds to \textit{any expression}, so forward search cannot enumerate every possible value of $\$b$). Moreover, the meet in the middle approach tends to be more effective than two rounds of only forward or backward search. 

We find the system is limited to two rounds of search under reasonable time constraints: an upper bound of 4 seconds, for students interacting with a web application. At each iteration of search DeduceIt applies the set of available rewrite rules---defined by the collection of rulesets---non-deterministically and exhaustively. 

\subsection{The Proof Cache}

The proof cache is a data structure DeduceIt uses to track all responses the frontend application receives from the prover. This cache is composed of many proof trees, one for each assignment, and together these proof trees track the aggregate history of every attempted derivation (as we discussed in the previous section). Proof trees are useful enough for managing assignments---through them an instructor can annotate derivation steps and override the default behavior of the prover---but they can also, by acting as a cache, potentially improve the overall performance of the system. To check a new derivation step using the proof cache, DeduceIt walks down the proof tree associated with that derivation's assignment: if the new step already exists in the tree, then the system doesn't need to query the prover; it simply returns the stored result.

We formed two hypotheses about the proof cache:
\begin{enumerate}
  \item Students tend to complete their derivations in similar ways; that is, they follow similar paths through an assignment's proof tree.
  \item It is more efficient to reuse the intermediate results of one student's derivation to check the validity of another student's derivation, when compared to checking every derivation step with the prover. 
\end{enumerate}  
  The second hypothesis seemed particularly likely to us since the cost of a checking a step with the prover is much higher than the cost of looking up a result in the cache. An average prover API query takes X seconds, whereas a typical cache lookup takes only Y seconds. We evaluate the performance impact of the proof cache more fully in the next section.

\section{Evaluation}

To better evaluate DeduceIt's usefulness, we deployed it in the winter offering of Coursera's \textit{Compilers} class, where we assigned each student two DeduceIt problems for every week of the course. Out of the 7625 students who enrolled in the course, 1788 of them participated actively, and 1000 of these students completed at least one DeduceIt assignment.

In this section we analyze several aspects of the system. We begin with a broad measure of system performance, then for a few representative assignments we look at: the distribution of students' time spent on derivations, the success rate of students, the average number of student errors, and the performance impact of the DeduceIt's proof cache.

Out of the 11 DeduceIt assignments, we chose Assignment1, Assignment2, and Assignment3. Assignment1 is something. Assignment2 is something. Assignment3 is something. These assignments were also chosen as examples which become progressively more difficult.

\subsection{System Performance}
\subsection{Student Time Distributions}
\subsection{Student Success Rates}
\subsection{Student Error Rates}
\subsection{Performance Impact of the Cache}

\section{Conclusions}

Anecdotal feedback and conclusions.

% \subsection{Normal or Body Text}
% 
% Please use a 10-point Times Roman font or, if this is unavailable,
% another proportional font with serifs, as close as possible in
% appearance to Times Roman 10-point. The Press 10-point font available
% to users of Script is a good substitute for Times Roman. If Times
% Roman is not available, try the font named Computer Modern Roman. On a
% Macintosh, use the font named Times and not Times New Roman. Please
% use sans-serif or non-proportional fonts only for special purposes,
% such as headings or source code text.
% 
% \subsection{First Page Copyright Notice}
% 
% Leave 3 cm (1.25 in.) of blank space for the copyright notice at the
% bottom of the left column of the first page. In this template a
% floating text box will automatically generate the required space. Note
% however that the text box is anchored to the \textbf{ABSTRACT}
% heading, so if that heading is deleted the text box will disappear as
% well.  You can replace the default copyright notice by uncommenting
% the {\textbackslash}toappear block at the beginning of the document
% and inserting your own text, for example, for versions under review.
% 
% \subsection{Subsequent Pages}
% 
% On pages beyond the first, start at the top of the page and continue
% in double-column format.  The two columns on the last page should be
% of equal length.
% 
% \begin{figure}[!h]
% \centering
% \includegraphics[width=0.9\columnwidth]{Figure1}
% \caption{With Caption Below, be sure to have a good resolution image
%   (see item D within the preparation instructions).}
% \label{fig:figure1}
% \end{figure}
% 
% \subsection{References and Citations}
% 
% Use a numbered list of references at the end of the article, ordered
% alphabetically by first author, and referenced by numbers in brackets
% \cite{ethics,
%   Klemmer:2002:WSC:503376.503378,
%   Mather:2000:MUT,
%   Zellweger:2001:FAO:504216.504224}. For
% papers from conference proceedings, include the title of the paper and
% an abbreviated name of the conference (e.g., for Interact 2003
% proceedings, use \textit{Proc. Interact 2003}). Do not include the
% location of the conference or the exact date; do include the page
% numbers if available. See the examples of citations at the end of this
% document. Within this template file, use the \texttt{References} style
% for the text of your citation.
% 
% Your references should be published materials accessible to the
% public.  Internal technical reports may be cited only if they are
% easily accessible (i.e., you provide the address for obtaining the
% report within your citation) and may be obtained by any reader for a
% nominal fee.  Proprietary information may not be cited. Private
% communications should be acknowledged in the main text, not referenced
% (e.g., ``[Robertson, personal communication]'').
% 
% \begin{table}
%   \centering
%   \begin{tabular}{|c|c|c|}
%     \hline
%     \tabhead{Objects} &
%     \multicolumn{1}{|p{0.3\columnwidth}|}{\centering\tabhead{Caption --- pre-2002}} &
%     \multicolumn{1}{|p{0.4\columnwidth}|}{\centering\tabhead{Caption --- 2003 and afterwards}} \\
%     \hline
%     Tables & Above & Below \\
%     \hline
%     Figures & Below & Below \\
%     \hline
%   \end{tabular}
%   \caption{Table captions should be placed below the table.}
%   \label{tab:table1}
% \end{table}
% 
% \section{Sections}
% 
% The heading of a section should be in Helvetica 9-point bold, all in
% capitals. Use Arial if Helvetica is not available. Sections should
% not be numbered.
% 
% \subsection{Subsections}
% 
% Headings of subsections should be in Helvetica 9-point bold with
% initial letters capitalized.  For
% sub-sections and sub-subsections, a word like \emph{the} or \emph{of}
% is not capitalized unless it is the first word of the heading.)
% 
% \subsubsection{Sub-subsections}
% 
% Headings for sub-subsections should be in Helvetica 9-point italic
% with initial letters capitalized.  Standard {\textbackslash}section,
% {\textbackslash}subsection, and {\textbackslash}subsubsection commands
% will work fine.
% 
% \section{Figures/Captions}
% 
% Place figures and tables at the top or bottom of the appropriate
% column or columns, on the same page as the relevant text
% (see Figure~\ref{fig:figure1}). A figure or table may extend across both
% columns to a maximum width of 17.78 cm (7 in.).
% 
% Captions should be Times New Roman 9-point bold.  They should be numbered (e.g.,
% ``Table~\ref{tab:table1}'' or ``Figure~\ref{fig:figure2}''), centered
% and placed beneath the figure or table.  Please note that the words
% ``Figure'' and ``Table'' should be spelled out (e.g., ``Figure''
% rather than ``Fig.'') wherever they occur.
% 
% Papers and notes may use color figures, which are included in the page
% limit; the figures must be usable when printed in black and white in
% the proceedings.  The paper may be accompanied by a short video figure
% up to five minutes in length.  However, the paper should stand on its
% own without the video figure, as the video may not be available to
% everyone who reads the paper.
% 
% \section{Language, Style and Content}
% 
% The written and spoken language of SIGCHI is English. Spelling and
% punctuation may use any dialect of English (e.g., British, Canadian,
% US, etc.) provided this is done consistently. Hyphenation is
% optional. To ensure suitability for an international audience, please
% pay attention to the following:
% 
% \begin{itemize}
% \item Write in a straightforward style.
% \item Try to avoid long or complex sentence structures.
% \item Briefly define or explain all technical terms that may be
%   unfamiliar to readers.
% \item Explain all acronyms the first time they are used in your text---e.g.,
% ``Digital Signal Processing (DSP)''.
% \item Explain local references (e.g., not everyone knows all city
%   names in a particular country).
% \item Explain ``insider'' comments. Ensure that your whole audience
%   understands any reference whose meaning you do not describe (e.g.,
%   do not assume that everyone has used a Macintosh or a particular
%   application).
% \item Explain colloquial language and puns. Understanding phrases like
%   ``red herring'' may require a local knowledge of English.  Humor and
%   irony are difficult to translate.
% \item Use unambiguous forms for culturally localized concepts, such as
%   times, dates, currencies and numbers (e.g., ``1-5-97'' or ``5/1/97''
%   may mean 5 January or 1 May, and ``seven o'clock'' may mean 7:00 am or
%   19:00).  For currencies, indicate equivalences---e.g., ``Participants
%   were paid 10,000 lire, or roughly \$5.''
% \item Be careful with the use of gender-specific pronouns (he, she)
%   and other gendered words (chairman, manpower, man-months). Use
%   inclusive language that is gender-neutral (e.g., she or he, they,
%   s/he, chair, staff, staff-hours,
%   person-years). See~\cite{Schwartz:1995:GBF} for further advice and
%   examples regarding gender and other personal attributes.
% \item If possible, use the full (extended) alphabetic character set
%   for names of persons, institutions, and places (e.g.,
%   Gr{\o}nb{\ae}k, Lafreni\'ere, S\'anchez, Universit{\"a}t,
%   Wei{\ss}enbach, Z{\"u}llighoven, \r{A}rhus, etc.).  These characters
%   are already included in most versions of Times, Helvetica, and Arial
%   fonts.
% \end{itemize}
% 
% \section{Page Numbering, Headers and Footers}
% 
% Please submit your anonymous version for reviewing with page numbers
% centered in the footer.  These must be removed in the final version of
% accepted papers, as page numbers, headers, and footers will be added
% by the conference printers.  Comment out the {\textbackslash}pagenumbering
% command at the top of the document to remove page numbers.
% 
% \section{Producing and Testing PDF Files}
% 
% We recommend that you produce a PDF version of your submission well
% before the final deadline.  Your PDF file must be ACM DL
% Compliant. The requirements for an ACM Compliant PDF are available at:
% {\url{http://www.sheridanprinting.com/typedept/ACM-distilling-settings.htm}}.
% 
% Test your PDF file by viewing or printing it with the same software we
% will use when we receive it, Adobe Acrobat Reader Version 7. This is
% widely available at no cost from~\cite{acrobat}.  Note that most
% reviewers will use a North American/European version of Acrobat
% reader, which cannot handle documents containing non-North American or
% non-European fonts (e.g. Asian fonts).  Please therefore do not use
% Asian fonts, and verify this by testing with a North American/European
% Acrobat reader (obtainable as above). Something as minor as including
% a space or punctuation character in a two-byte font can render a file
% unreadable.
% 
% \section{Blind Review}
% 
% For archival submissions, CHI requires a ``blind review.'' To prepare
% your submission for blind review, remove author and institutional
% identities in the title and header areas of the paper. You may also
% need to remove part or all of the Acknowledgments text.  Further
% suppression of identity in the body of the paper and references is
% left to the authors' discretion. For more details, see the submission
% guidelines and checklist for your submission category.
% 
% \section{Conclusion}
% 
% It is important that you write for the SIGCHI audience.  Please read
% previous years' Proceedings to understand the writing style and
% conventions that successful authors have used.  It is particularly
% important that you state clearly what you have done, not merely what
% you plan to do, and explain how your work is different from previously
% published work, i.e., what is the unique contribution that your work
% makes to the field?  Please consider what the reader will learn from
% your submission, and how they will find your work useful.  If you
% write with these questions in mind, your work is more likely to be
% successful, both in being accepted into the Conference, and in
% influencing the work of our field.
% 
% \section{Acknowledgments}
% 
% We thank CHI, PDC and CSCW volunteers, and all publications support
% and staff, who wrote and provided helpful comments on previous
% versions of this document.  Some of the references cited in this paper
% are included for illustrative purposes only.  \textbf{Don't forget
% to acknowledge funding sources as well}, so you don't wind up
% having to correct it later.

% Balancing columns in a ref list is a bit of a pain because you
% either use a hack like flushend or balance, or manually insert
% a column break.  http://www.tex.ac.uk/cgi-bin/texfaq2html?label=balance
% multicols doesn't work because we're already in two-column mode,
% and flushend isn't awesome, so I choose balance.  See this
% for more info: http://cs.brown.edu/system/software/latex/doc/balance.pdf
%
% Note that in a perfect world balance wants to be in the first
% column of the last page.
%
% If balance doesn't work for you, you can remove that and
% hard-code a column break into the bbl file right before you
% submit:
%
% http://stackoverflow.com/questions/2149854/how-to-manually-equalize-columns-
% in-an-ieee-paper-if-using-bibtex
%
% Or, just remove \balance and give up on balancing the last page.
%
\balance

% If you want to use smaller typesetting for the reference list,
% uncomment the following line:
% \small
\bibliographystyle{acm-sigchi}
\bibliography{sample}
\end{document}
